{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.distributed import destroy_process_group, init_process_group\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "\n",
    "from model import GPT\n",
    "from trainer import Trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filepath):\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as file:\n",
    "        return file.read() + \"\\n\"\n",
    "\n",
    "\n",
    "def read_all_files_to_string(directory):\n",
    "    filepaths = [\n",
    "        filepath\n",
    "        for filepath in glob.glob(os.path.join(directory, \"**\", \"*\"), recursive=True)\n",
    "        if os.path.isfile(filepath)\n",
    "    ]\n",
    "\n",
    "    if not filepaths:\n",
    "        raise ValueError(\"No files found in the input directory.\")\n",
    "\n",
    "    combined_string = \"\"\n",
    "    with mp.Pool(min(len(filepaths), mp.cpu_count())) as executor:\n",
    "        results = executor.map(read_file, filepaths)\n",
    "        combined_string = \"\".join(results)\n",
    "\n",
    "    return combined_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "def prepare_data(text: str, vocab_limit: int):\n",
    "    if not text:\n",
    "        raise ValueError(\n",
    "            \"The input text is empty. Please check the file reading process.\"\n",
    "        )\n",
    "\n",
    "    lines = text.splitlines()\n",
    "    lines = [line for line in lines if all(c.isascii() for c in line)]\n",
    "\n",
    "    if not lines:\n",
    "        raise ValueError(\"No valid ASCII lines found in the input text.\")\n",
    "\n",
    "    word_counts = Counter(word for line in lines[:100_000] for word in line.split())\n",
    "\n",
    "    most_common_words = [word for word, _ in word_counts.most_common(vocab_limit)]\n",
    "    words = most_common_words + [\"<unk>\", \"\\n\"]\n",
    "\n",
    "    vocab_size = len(words)\n",
    "    stoi = {word: i for i, word in enumerate(words)}\n",
    "    itos = {i: word for i, word in enumerate(words)}\n",
    "\n",
    "    def encode(sentence):\n",
    "        tokens = [\n",
    "            stoi[word] if word in stoi else stoi[\"<unk>\"] for word in sentence.split()\n",
    "        ]\n",
    "        tokens.append(stoi[\"\\n\"])\n",
    "        return tokens\n",
    "\n",
    "    def decode(tokens):\n",
    "        words = [itos[token] for token in tokens]\n",
    "        return \" \".join(words).replace(\" \\n\", \"\\n\")\n",
    "\n",
    "    encoded_lines = [\n",
    "        torch.tensor(encode(line), dtype=torch.long) for line in lines if encode(line)\n",
    "    ]\n",
    "\n",
    "    if not encoded_lines:\n",
    "        raise ValueError(\"No lines were encoded. Check the encoding process.\")\n",
    "\n",
    "    return torch.cat(encoded_lines), encode, decode, vocab_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, data, block_size):\n",
    "        self.data = data\n",
    "        self.block_size = block_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.block_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx : idx + self.block_size]\n",
    "        y = self.data[idx + 1 : idx + self.block_size + 1]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "block_size = 128\n",
    "max_epochs = 2000\n",
    "learning_rate = 3e-4\n",
    "n_embd = 384\n",
    "n_head = 6\n",
    "n_layer = 6\n",
    "dropout = 0.2\n",
    "save_interval = 10\n",
    "num_groups = 3\n",
    "vocab_limit = 10_000\n",
    "\n",
    "eval_str = r\"\"\"\n",
    "    Scene 1\n",
    "=======\n",
    "[Enter Theseus, Hippolyta, and Philostrate, with others.]\n",
    "\n",
    "\n",
    "THESEUS\n",
    "Now, fair Hippolyta, our nuptial hour\n",
    "Draws on apace. Four happy days bring in\n",
    "Another moon. But, O, methinks how slow\n",
    "This old moon wanes! She lingers my desires\n",
    "Like to a stepdame or a dowager\n",
    "Long withering out a young man's revenue.\n",
    "\n",
    "HIPPOLYTA\n",
    "Four days will quickly steep themselves in night;\n",
    "Four nights will quickly dream away the time;\n",
    "And then the moon, like to a silver bow\n",
    "New-bent in heaven, shall behold the night\n",
    "Of our solemnities.\n",
    "\n",
    "THESEUS  Go, Philostrate,\n",
    "Stir up the Athenian youth \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2129633\n"
     ]
    }
   ],
   "source": [
    "directory = \"data\"\n",
    "snapshot_path = f\"{directory.replace('/', '_')}.pt\"\n",
    "\n",
    "text = read_all_files_to_string(directory)\n",
    "train_data, encode, decode, vocab_size = prepare_data(text, vocab_limit)\n",
    "print(vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ddp_setup():\n",
    "    torch.cuda.set_device(int(os.environ[\"LOCAL_RANK\"]))\n",
    "    init_process_group(backend=\"nccl\")\n",
    "\n",
    "\n",
    "def load_train_objs():\n",
    "    train_dataset = TextDataset(train_data, block_size)\n",
    "\n",
    "    model = GPT(\n",
    "        vocab_size,\n",
    "        n_embd,\n",
    "        block_size,\n",
    "        n_layer,\n",
    "        n_head,\n",
    "        dropout,\n",
    "        num_groups,\n",
    "    )\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    return train_dataset, model, optimizer\n",
    "\n",
    "\n",
    "def prepare_dataloader(dataset: Dataset, batch_size: int):\n",
    "    return DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        pin_memory=True,\n",
    "        shuffle=False,\n",
    "        sampler=DistributedSampler(dataset),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddp_setup()\n",
    "dataset, model, optimizer = load_train_objs()\n",
    "train_loader = prepare_dataloader(dataset, batch_size)\n",
    "trainer = Trainer(model, train_loader, optimizer, save_interval, snapshot_path)\n",
    "trainer.train(max_epochs)\n",
    "destroy_process_group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_183747/171385888.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(snapshot_path)[\"MODEL_STATE\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scene 1 ======= [Enter Theseus, Hippolyta, and Philostrate, with others.] THESEUS Now, fair Hippolyta, our nuptial hour Draws on apace. Four happy days bring in Another moon. But, O, methinks how slow This old moon wanes! She lingers my desires Like to a stepdame or a dowager Long withering out a young man's revenue. HIPPOLYTA Four days will quickly steep themselves in night; Four nights will quickly dream away the time; And then the moon, like to a silver bow New-bent in heaven, shall behold the night Of our solemnities. THESEUS Go, Philostrate, Stir up the Athenian youth\n",
      " Make his trotting Northumberland, I checked my Proculeius, and credulous!\n",
      " Where one children's devil shall be Mantua,\n",
      " And the murder; and weary, find: with a pate\n",
      " breed the fatal appall bearing Sailor thou rebellion to dreamed gashes\n",
      " There was she, footing of their Lords.]\n",
      " Shall passing them mood\n",
      " [The Play conscience,\n",
      " And for he lament'st. of hath bloody heaven by our owe;\n",
      " costume.)]\n",
      " Now, but several King that way to th' swords.\n",
      "\n",
      " The gods my lord?\n",
      " There is his death.\n",
      " To make his most Roman gate.\n",
      " PLAYER Now if thou to\n",
      " EMILIA\n",
      " Sound a King is revenge, Now, bragging thought\n",
      "\n",
      " 'Twere tempts all his array, he fell.\n",
      " Thy wrong together\n",
      " The fittest christened keep friend, who lodge from\n",
      " And become a ladies thy moved\n",
      " The wrongs that her defiled long show the whole, and he is!\n",
      " The most wormy devour!\n",
      " And perhaps see the breasts in what, unless we so sing'st and need.\n",
      " Have valiant--\n",
      "\n",
      " Not not need and the god she would you!\n",
      " Of silver faith a issue of the sky.\n",
      " And much my heart, but toast at her mistrust\n",
      " Which will live to them.]\n",
      "\n",
      " Which will have very weak sin,\n",
      " Or his hair, thou come all that I'll rest and profit,\n",
      " The spring hold the war,\n",
      " Or feeds three sense for their Grecian nature. [He wouldst my morrow.\n",
      " What, find pale and me.\n",
      " And in pound!\n",
      "\n",
      " Their Men]\n",
      " valorously known on the Nestor.\n",
      " From hand hoarse, whose vow at deeds of love\n",
      " Cry thy Shakespeare\n",
      " asks up my better answered,\n",
      " That top!\n",
      "\n",
      " HAMLET\n",
      " In but, will learn the father shall be not blood. The day\n",
      " Or too burgonet of a Cleon knight.\n",
      " That you are long in your own lecture\n",
      " All kings at King Snakes lives in bachelor and before his worldly Bordeaux\n",
      " votary for my chastisement.\n",
      " To speak and their wanton faults\n",
      " wrongs?\n",
      " And to your general gone?\n",
      " The English King, already.\n",
      "\n",
      " ALBANY A lady of my life, impair my God whereupon\n",
      " And to news made peace. If\n",
      "\n",
      " And subject lived from excellence. Why have no heart,\n",
      " The eastern proportion of every soul;\n",
      " Martians, as fast some which I have unfold,\n",
      " Our modest apparel up.\n",
      " Say him win his venomed cause, but a t'other d' I\n",
      " Which will cool 'tis\n",
      " SERVILIUS Now doth infection perverse\n",
      " Commend you, so, and alone?\n",
      " 'Tis listened Mars, truly two Rome; for the net.]\n",
      " SILVIUS\n",
      " Of Rome his Ligarius, mark so it say\n",
      " And sure, and soldiers,\n",
      " And can so expiration of the WATCH\n",
      " The eyes to cross all Henry's coward ladies,\n",
      " And but to the ire Henry, tougher, days.\n",
      " A pride of you please yourself.\n",
      " Thy gaze to try the hearers of Rome, Being not press of her\n",
      " Unless that see humor are sixteen I sit down\n",
      " And whoreson --he wears heaven?\n",
      " Parcel this heart noble,\n",
      " Before the best pour the demerits, how first burn is the wise visible queen, serpent\n",
      "\n",
      " MESSENGER OF shall see me? [He Geoffrey\n",
      " Being not arise an wilt is the Tarquin tears\n",
      " tender serpents of an contempt.\n",
      " Swarming outstrip\n",
      " Go all intrude thou dost the matter?\n",
      " Deceitful souls that fly him; being a curate.\n",
      " This is full of wars with me\n",
      " When a sting?\n",
      " Scene 1\n",
      " [Enter Philotus.]\n",
      "\n",
      " Good Jailer, at Lord to the prince's reason and strong every bosom.\n",
      "\n",
      " Troy; the Robin Study\n",
      " MESSENGER\n",
      " CARLISLE\n",
      " LUCETTA\n",
      " FIRST GENTLEMAN There's Desdemona's boy; thou it to the aspects.\n",
      " The wait. I would not speak thanks most a\n",
      " And tribute, in the\n",
      " To receive it Andronicus, if a making?\n",
      " \"I will not Ganymede]\n",
      " And hold any flight is mine own and I do that do shamed another fair\n",
      " shunning in the there--and 's king.\n",
      "\n",
      " [Enter feed.\n",
      "\n",
      "\n",
      " KING Away, sir, it twinkle to Milan, as here's 't--and\n",
      " Women love you?\n",
      "\n",
      "\n",
      " Bertram.\n",
      " GONERIL Come yourself, and commissions\n",
      " If I had used?\n",
      " More life thither take me for the victor's aid,\n",
      " Such wealth comes upon the cup.]\n",
      "\n",
      " The division. Bravest to the time to season to marry this other\n",
      " And they will neck,\" good truly, under his\n",
      " Cries my nurse? [Executioners Lord alarum is strong Caesar Death's\n",
      " But had so much woman that twenty in the heat\n",
      " Have not your OUTLAW\n",
      " O'er these valiant lord, it is the cheer our word, most time set the Vaudemont\n",
      " When I called whom it would he was a sakes stay\n",
      " Hers, bush. Let's never good,\n",
      " Th' gods on the outward melody.\n",
      " But replies.\n",
      " Think is madness.\n",
      " Remains the Mass, you are sick, if three Antonio.\n",
      "\n",
      " Think month, and will pursue performed why she hath Malvolio away. Look\n",
      " But in pain of all whom a intelligence from my great\n",
      " marked, and the offending and make him\n",
      " Or to wait Chrish, a brazen casing shoulder\n",
      " begins to be but know.\n",
      "\n",
      " Upon the city\n",
      " And wholesome ancestors,\n",
      " Ay. Thou can make a beauty of a rite is\n",
      " If, good drew and good, and his hope\n",
      " possessed, said; my age and in his lord.--Come Master Sir mine ball Hacked he months,\n",
      " monument,\n",
      " Round nothing strong, of Razeth his command.\n",
      "\n",
      " GLOUCESTER\n",
      " FIRST Worship seems thou \"What's his own tenfold Ligarius, hath dead.\n",
      "\n",
      " Thy honor, fair and harum, Fluellen.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = GPT(\n",
    "    vocab_size,\n",
    "    n_embd,\n",
    "    block_size,\n",
    "    n_layer,\n",
    "    n_head,\n",
    "    dropout,\n",
    "    num_groups,\n",
    ").cuda()\n",
    "\n",
    "model.load_state_dict(torch.load(snapshot_path)[\"MODEL_STATE\"])\n",
    "context = torch.tensor([encode(eval_str)], dtype=torch.long).cuda()\n",
    "print(decode(model.generate(context, max_new_tokens=1000)[0].tolist()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
